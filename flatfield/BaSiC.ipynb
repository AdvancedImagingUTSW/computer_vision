{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "1. np.matlib is used where it was hard to find a Python translate on the fly due to the long and not-readable original Matlab code\n",
    "2. There are several spots in the Matlab code that it uses **(:)** in order to linearize a matrix. There are two ways to perfom this in Python: By using numpy's **reshape()** function (meanD.shape[0]\\*meanD.shape[1], 1) OR by using numpy's **flatten()** function. Both are used but flatten is a better a solution becaue of readability. Here is a one major difference though: **x1 = img1.flatten()** is of shape **(N,)** but **x2 = np.reshape(img1, (img1.shape[0]\\*img1.shape[1],1))** is of shape **(N,1)**, so I think it would be safer to use the np.reshape(). However, the results for np.divide(np.sum(np.abs(**x1**)), 400\\*0.5) is the same as np.divide(np.sum(np.abs(**x2**)), 400\\*0.5).\n",
    "3. Indexing in Python starts from zero while in Matlab starts from one, so for example mean(D,3) in Matlab is the same as np.mean(D, axis = 2)\n",
    "4. mean(D) in Matlab is the same as np.mean(D,0) in Python, which is mean across columns (5 x 3) -> 1 x 3\n",
    "5. To Do: Write a parse config function\n",
    "6. Python indexing different from Matlab indexing, so find() in Matlab can not be used in Python\n",
    "7. np.tile() is the equivalent of Matlab's repmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "import numpy as np\n",
    "from scipy.fftpack import fft, dct, idct\n",
    "import skimage.transform\n",
    "from numpy import linalg as LA\n",
    "from PIL import Image\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To Do: write function for parsing options from a .yaml file\n",
    "options = {\n",
    "    'working_size' : 4 , # change based on your input data\n",
    "    'darkfield' : True ,\n",
    "    'basefluo' : False ,\n",
    "    'lambda' : 0.0001 ,\n",
    "    'lambda_dark' : 0.0001 ,\n",
    "    'lambda_darkfield' : 0.0001,\n",
    "    'optimization_tol' : 0.001 ,\n",
    "    'max_iterations' : 500,\n",
    "    'estimation_mode' : 'l0',\n",
    "    'reweight_tol' : 0.004 , # please change\n",
    "    'max_reweightiterations' : 50 , # please change\n",
    "    'epsilon' : 0.001 # please change - also do thet meant epsilon?? \n",
    "    \n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inexact_alm_rspca_l1(D, weight, tol, maxIter, darkfield_flag, options):\n",
    "    \n",
    "    # weight: np.ones OR one\n",
    "    # darkfield_flag: true OR false\n",
    "    # B1_uplimit : darkfieldlimit OR 1e7\n",
    "    \n",
    "    # intialization and given default variables  \n",
    "    p = D.shape[0]\n",
    "    q = D.shape[1]\n",
    "    m = p*q\n",
    "    n = D.shape[2]\n",
    "    \n",
    "    D = D.reshape(m,n, order='F')\n",
    "    # Todo: if weight is empty, u, s, vh = np.linalg.svd(D, full_matrices=False)set to one\n",
    "    weight = weight.reshape(D.shape)\n",
    "    \n",
    "    u, s, vh = np.linalg.svd(D, full_matrices=False)\n",
    "    norm_two = s[0]\n",
    "    # Todo:clear u,s,vh\n",
    "    \n",
    "    Y1 = 0\n",
    "    Y2 = 0\n",
    "    ent1 = 1\n",
    "    ent2 = 10\n",
    "\n",
    "    A1_hat = np.zeros(D.shape)\n",
    "    E1_hat = np.zeros(D.shape)\n",
    "    #W_hat = mirt_dct2(mean(reshape(A1_hat,p,q,n),3));\n",
    "    W_hat = dct(dct(np.mean(A1_hat.reshape(p,q,n), 2), norm='ortho'),axis=-2,norm='ortho')\n",
    "    mu = 12.5/norm_two# this one can be tuned\n",
    "    mu_bar = mu * 1e7\n",
    "    rho = 1.5          # this one can be tuned\n",
    "    d_norm = np.linalg.norm(D, ord='fro')\n",
    "    A1_coeff = np.ones((1,n), dtype=float)\n",
    "    A_offset = np.zeros((m,1), dtype=float)\n",
    "    B1_uplimit = np.min(D)\n",
    "    B1_offset = 0\n",
    "    #A_uplimit = min(D,[],2)\n",
    "    A_uplimit = np.min(D, 1) # Todo: This gives horizontal vector, but matlab one gives vertical\n",
    "    A_uplimit = A_uplimit.reshape(A_uplimit.size, 1)\n",
    "    A_inmask = np.zeros((p,q), dtype=float)\n",
    "    A_inmask[int(np.round(p/6)):int(np.round(p*5/6)),int(np.round(q/6)):int(np.round(q*5/6))] = 1\n",
    "    # main iteration loop starts\n",
    "    itr = 0\n",
    "    total_svd = 0\n",
    "    converged = False\n",
    "    print('Starting while loop...')\n",
    "    while (not converged):\n",
    "        itr = itr + 1 \n",
    "        W_hat = W_hat.transpose()\n",
    "        W_idct_hat = idct(idct(W_hat, norm='ortho'),axis=-2,norm='ortho') # \n",
    "        A1_hat = (W_idct_hat.reshape(W_idct_hat.size,1) * A1_coeff) + A_offset\n",
    "        temp_W = np.divide((D - A1_hat - E1_hat + (1/mu)*Y1 ),ent1) #  Todo: np.substract?\n",
    "        temp_W = temp_W.reshape(p,q,n)\n",
    "        temp_W = np.mean(temp_W,2)\n",
    "        W_hat = W_hat + dct(dct(temp_W, norm='ortho'),axis=-2,norm='ortho') # Todo: is W_hat a row vector?\n",
    "        W_hat = np.maximum(W_hat - (options['lambda']/(ent1*mu)),0) + np.minimum(W_hat + (options['lambda']/(ent1*mu)),0)\n",
    "        W_idct_hat = idct(idct(W_hat, norm='ortho'),axis=-2,norm='ortho')\n",
    "        A1_hat = (W_idct_hat.reshape(W_idct_hat.size,1) * A1_coeff) + A_offset\n",
    "        E1_hat = E1_hat + D - A1_hat - E1_hat + (1/mu)*Y1/ent1\n",
    "        E1_hat = np.maximum(E1_hat - weight/(ent1*mu), 0)+ np.minimum(E1_hat + weight/(ent1*mu), 0)\n",
    "        R1 = D - E1_hat\n",
    "        A1_coeff = np.divide(np.mean(R1,0),np.mean(R1))\n",
    "        A1_coeff = A1_coeff.reshape(1, A1_coeff.size)\n",
    "        A1_coeff[A1_coeff<0] = 0\n",
    "        if darkfield_flag == 1: \n",
    "            #validA1coeff_idx = find(A1_coeff<1);\n",
    "            #B1_coeff = (mean(R1(W_idct_hat(:)>mean(W_idct_hat(:))-1e-6,validA1coeff_idx))-mean(R1(W_idct_hat(:)<mean(W_idct_hat(:))+1e-6,validA1coeff_idx)))./mean(R1(:));\n",
    "            validA1coeff_idx = np.argwhere(A1_coeff<1)\n",
    "            idx = validA1coeff_idx[:,1]\n",
    "            if (validA1coeff_idx.size != 0):\n",
    "                temp1 = W_idct_hat.reshape(W_idct_hat.size,1)>np.mean(W_idct_hat)-1e-6\n",
    "                temp_mat_1 = R1[temp1[:,0],idx[0]]\n",
    "                for i in range(1,idx.size):\n",
    "                    temp_mat_1 = np.hstack((temp_mat_1, R1[temp1[:,0],idx[i]]))\n",
    "                #temp_mat_1 = np.reshape(temp_mat_1, (int(temp_mat_1.shape[0]/idx.size), idx.size))\n",
    "            \n",
    "                temp2 = W_idct_hat.reshape(W_idct_hat.size,1)<np.mean(W_idct_hat)+1e-6\n",
    "                temp_mat_2 = R1[temp2[:,0],idx[0]]\n",
    "                for i in range(1,idx.size):\n",
    "                    temp_mat_2 = np.hstack((temp_mat_2, R1[temp2[:,0],idx[i]]))\n",
    "                #temp_mat_2 = np.reshape(temp_mat_2, (int(temp_mat_2.shape[0]/idx.size), idx.size))\n",
    "                B1_coeff = np.divide((np.mean(temp_mat_1,0)-np.mean(temp_mat_2,0)),np.mean(R1))\n",
    "                #B1_coeff = (mean(R1(W_idct_hat(:)>mean(W_idct_hat(:))-1e-6,validA1coeff_idx[:,0]))-mean(R1(W_idct_hat(:)<mean(W_idct_hat(:))+1e-6,validA1coeff_idx[:,0])))./mean(R1(:));\n",
    "                \n",
    "                k = np.size(idx)   \n",
    "                temp1 = np.sum(A1_coeff[0,idx]**2)\n",
    "                temp2 = np.sum(A1_coeff[0,idx]) \n",
    "                temp3 = np.sum(B1_coeff)\n",
    "                temp4 = np.sum(A1_coeff[0,idx]*B1_coeff)\n",
    "                temp5 = temp2 * temp3 - (k*temp4)\n",
    "                if temp5 == 0:\n",
    "                    B1_offset = 0\n",
    "                else:\n",
    "                    B1_offset = np.divide((temp1 * temp3 - temp2 * temp4), temp5)\n",
    "               \n",
    "               \n",
    "                B1_offset = np.maximum(B1_offset,0)\n",
    "                B1_offset = np.minimum(B1_offset, np.divide(B1_uplimit, np.mean(W_idct_hat)))\n",
    "                B_offset = np.multiply(B1_offset, np.mean(W_idct_hat)) - np.multiply(B1_offset, W_idct_hat.reshape(W_idct_hat.size,1))\n",
    "                temp_mat = R1[:,idx[0]]\n",
    "                temp_mat = temp_mat.reshape(temp_mat.size,1)\n",
    "                for i in range(1,idx.size):\n",
    "                    temp_R = R1[:,idx[i]]\n",
    "                    temp_R = temp_R.reshape(temp_R.size,1)\n",
    "                    temp_mat = np.hstack((temp_mat, temp_R))\n",
    "                \n",
    "                temp = np.mean(temp_mat,1) - np.mean(A1_coeff[0,idx])\n",
    "                A1_offset = np.multiply(temp.reshape(temp.size, 1), W_idct_hat.reshape(W_idct_hat.size, 1))\n",
    "                #A1_offset = mean(R1(:,validA1coeff_idx[:,0]),2)-mean(A1_coeff(validA1coeff_idx[:,0])).*W_idct_hat(:);\n",
    "                A1_offset = np.subtract(A1_offset, np.mean(A1_offset))\n",
    "                A_offset = np.subtract(A1_offset, np.mean(A1_offset)) - B_offset\n",
    "           \n",
    "                W_offset = dct(dct(A_offset.reshape(p,q), norm='ortho'),axis=-2,norm='ortho')\n",
    "                W_offset =  np.maximum(np.subtract(W_offset, options['lambda_darkfield']/ent2*mu),0) + np.minimum(np.add(W_offset, options['lambda_darkfield']/ent2*mu),0)\n",
    "                A_offset= idct(idct(W_offset, norm='ortho'),axis=-2,norm='ortho')\n",
    "                A_offset = A_offset.reshape(A_offset.size,1)\n",
    "           \n",
    "                A_offset = np.maximum(A_offset - options['lambda_darkfield']/(ent2*mu), 0.0) + np.minimum(A_offset + options['lambda_darkfield']/(ent2*mu), 0.0)          \n",
    "                A_offset = A_offset + B_offset\n",
    "            else:\n",
    "                W_offset = np.zeros((p,q), dtype=float)\n",
    "                B_offset = np.zeros((p*q,1), dtype=float)\n",
    "                A_offset= idct(idct(W_offset, norm='ortho'),axis=-2,norm='ortho')\n",
    "                A_offset = A_offset.reshape(A_offset.size,1)\n",
    "           \n",
    "                A_offset = np.maximum(A_offset - options['lambda_darkfield']/(ent2*mu), 0.0) + np.minimum(A_offset + options['lambda_darkfield']/(ent2*mu), 0.0)          \n",
    "                A_offset = A_offset + B_offset\n",
    "            \n",
    "            \n",
    "                                                                                 \n",
    "        Z1 = D - A1_hat - E1_hat\n",
    "        Y1 = Y1 + np.multiply(mu,Z1)\n",
    "        mu = np.minimum(mu*rho, mu_bar)\n",
    "        \n",
    "        # stop Criterion  \n",
    "        stopCriterion = np.linalg.norm(Z1, ord='fro') / d_norm\n",
    "    \n",
    "        if stopCriterion < tol:\n",
    "            converged = True\n",
    "            #A_offset = A_offset + B1_offset * W_idct_hat.reshape(W_idct_hat.size,1)\n",
    "            #return A1_hat, E1_hat, A_offset\n",
    "        \n",
    "        if np.mod( total_svd, 10) == 0:\n",
    "            print('Iteration ' , itr, ' |W|_0 ' , np.sum(np.abs(W_hat.reshape(W_hat.size,1))>0),\n",
    "            ' |E1|_0 ', np.sum((np.abs(E1_hat.reshape(E1_hat.size,1)>0))),\n",
    "            ' stopCriterion ', stopCriterion,\n",
    "            ' B1_offset ', B1_offset)\n",
    "            #A_offset = A_offset + B1_offset * W_idct_hat.reshape(W_idct_hat.size,1)\n",
    "            #return A1_hat, E1_hat, A_offset\n",
    "                                                                                 \n",
    "        if not converged and itr >= maxIter:\n",
    "            print('Maximum iterations reached') \n",
    "            converged = True\n",
    "            #A_offset = A_offset + B1_offset * W_idct_hat.reshape(W_idct_hat.size,1)\n",
    "            #return A1_hat, E1_hat, A_offset\n",
    "    \n",
    "    A_offset = A_offset + B1_offset * W_idct_hat.reshape(W_idct_hat.size,1)\n",
    "    return A1_hat, E1_hat, A_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def BaSiC(IF, options):\n",
    "    \n",
    "     # set default values for options that are not specified\n",
    "    if options['estimation_mode'] is None:\n",
    "        options['estimation_mode'] = 'l0'\n",
    "\n",
    "    if options['max_iterations'] is None:\n",
    "        options['max_iterations'] = 500\n",
    "        \n",
    "    if options['optimization_tol']:\n",
    "        options['optimization_tol'] = 1e-6\n",
    "\n",
    "    if options['darkfield'] is None:\n",
    "        options['darkfield'] = 'false'\n",
    "\n",
    "    nrows = options['working_size']\n",
    "    ncols = options['working_size'] # seems to be redundant \n",
    "    #D = scipy.misc.imresize(IF, [nrows, ncols], interp='bilinear')\n",
    "    D = skimage.transform.resize(IF, [nrows, ncols])\n",
    "    meanD = np.mean(D, axis = 2) # e.q. of mean(D,3) in Matlab\n",
    "    meanD = np.divide(meanD, np.mean(np.reshape(meanD, (meanD.shape[0]*meanD.shape[1], 1)))) # meanD is a two dim matrix\n",
    "    W_meanD = dct(meanD)\n",
    "    \n",
    "    if options['lambda'] is None: \n",
    "        options['lambda'] = np.divide(np.sum(np.abs(W_meanD.flatten('F'))), 400*0.5)\n",
    "    if options['lambda_darkfield'] is None:\n",
    "        options['lambda_darkfield'] = np.divide(np.sum(np.abs(W_meanD.flatten('F'))), 400*0.2)\n",
    "        \n",
    "    D = np.sort(D,2); # e.q. of sort(D,3) in Matlab\n",
    "    x,y,z = D.shape\n",
    "    for i in range(0,z):\n",
    "        D[:,:,i] = D[:,:,i].transpose(0,1)\n",
    "    XAoffset = np.zeros([nrows,ncols])\n",
    "    \n",
    "\n",
    "    weight = np.ones(D.shape)\n",
    "    i = 0\n",
    "    flag_reweighting = True\n",
    "    flatfield_last = np.ones([nrows,ncols])\n",
    "    darkfield_last = np.random.randn(nrows,ncols)\n",
    "    \n",
    "    \n",
    "    while (flag_reweighting and i < 3):\n",
    "        i = i+1\n",
    "        print('Reweighting Iteration ', i)\n",
    "        try:\n",
    "            X_k_A, X_k_E, X_k_Aoffset = inexact_alm_rspca_l1(D, np.ones(IF.shape, dtype=float), 0.001, 2, 1, options)\n",
    "            XA = np.reshape(X_k_A, [nrows, ncols, IF.shape[2]])\n",
    "            XE = np.reshape(X_k_E, [nrows, ncols, IF.shape[2]])\n",
    "            XAoffset = np.reshape(X_k_Aoffset, [nrows, ncols])\n",
    "            size_XA_z = XA.shape[2]\n",
    "            mean_XA = np.zeros((1,1,size_XA_z), dtype=float)\n",
    "            for i in range(0,size_XA_z):\n",
    "                mean_XA[:,:,i] = np.mean(XA[:,:,i])\n",
    "            \n",
    "            temp1 = np.tile(mean_XA, (nrows, ncols, 1)) \n",
    "            XE_norm = np.divide(XE, temp1 + 1e-6)\n",
    "            \n",
    "            weight = np.divide(1.0, np.add(np.abs(XE_norm), options['epsilon']))\n",
    "            weight = weight * np.size(weight) / np.sum(weight)\n",
    "            \n",
    "            temp = np.mean(XA, 2) - XAoffset\n",
    "            \n",
    "            flatfield_current = np.divide(temp, np.mean(temp))\n",
    "            \n",
    "            darkfield_current = XAoffset\n",
    "            mad_flatfield = np.divide(np.sum(np.abs(flatfield_current.flatten('F') - flatfield_last.flatten('F'))), np.sum(np.abs(flatfield_last.flatten('F'))))\n",
    "            \n",
    "            temp_diff = np.sum(np.abs(darkfield_current.flatten('F') - darkfield_last.flatten('F')))\n",
    "            \n",
    "            if (temp_diff < 1e-7):\n",
    "                mad_darkfield = 0\n",
    "            else:\n",
    "                temp_max = np.maximum(np.sum(np.abs(darkfield_last.flatten('F'))), 1)\n",
    "                mad_darkfield = temp_diff / temp_max\n",
    "\n",
    "            \n",
    "            flatfield_last = flatfield_current\n",
    "            darkfield_last = darkfield_current\n",
    "            if np.maximum(mad_flatfield, mad_darkfield) <= options['reweight_tol'] or i > options['max_reweightiterations']:\n",
    "                flag_reweighting = 0\n",
    "        except Exception as e:\n",
    "            exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "            print(exc_type, fname, exc_tb.tb_lineno)\n",
    "            print(e)\n",
    "       \n",
    "    shading =  np.mean(XA,2) - XAoffset\n",
    "    #XAoffset = XAoffset+B_offset.*shading;\n",
    "    flatfield = scipy.misc.imresize(shading, [IF.shape[0], IF.shape[1]])\n",
    "    flatfield = np.divide(flatfield, np.mean(flatfield.flatten('F')))\n",
    "    if options['darkfield']:\n",
    "        darkfield = XAoffset\n",
    "        #darkfield = scipy.misc.imresize(np.reshape(XAoffset,(nrows,ncols,1)),[IF.shape[0], IF.shape[1]])\n",
    "    else:\n",
    "        darkfield = np.empty # Seems unnecessary\n",
    "    \n",
    "    \n",
    "    return darkfield"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLabCut (myenv)",
   "language": "python",
   "name": "deeplab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
